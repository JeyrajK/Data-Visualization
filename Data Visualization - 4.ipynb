{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
    "    \n",
    "   * Tracking and visualizing metrics such as loss and accuracy\n",
    "   * Visualizing the model graph (ops and layers)\n",
    "   * Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "   * Projecting embeddings to a lower dimensional space\n",
    "   * Displaying images, text, and audio data\n",
    "   * Profiling TensorFlow programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Gifs/tensorboard-word-emb-gif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Gifs/tensorboard-dif-visu-gif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Gifs/tensorboard-img-gif.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "### Scalar Dashboard\n",
    "    TensorBoard's Scalar Dashboard visualizes scalar statistics that vary over time; for example, you might want to track the model's loss or learning rate. you can compare multiple runs, and the data is organized by tag. The line charts have the following interactions:\n",
    "\n",
    "    Clicking on the small blue icon in the lower-left corner of each chart will expand the chart\n",
    "\n",
    "    Dragging a rectangular region on the chart will zoom in\n",
    "\n",
    "    Double clicking on the chart will zoom out\n",
    "\n",
    "    Mousing over the chart will produce crosshairs, with data values recorded in the run-selector on the left.\n",
    "\n",
    "    Additionally, you can create new folders to organize tags by writing regular expressions in the box in the top-left of the dashboard.\n",
    "\n",
    "### Histogram Dashboard\n",
    "    The HistogramDashboard displays how the statistical distribution of a Tensor has varied over time. It visualizes data recorded via tf.summary.histogram. Each chart shows temporal \"slices\" of data, where each slice is a histogram of the tensor at a given step. It's organized with the oldest timestep in the back, and the most recent timestep in front. By changing the Histogram Mode from \"offset\" to \"overlay\", the perspective will rotate so that every histogram slice is rendered as a line and overlaid with one another.\n",
    "\n",
    "### Distribution Dashboard\n",
    "    The Distribution Dashboard is another way of visualizing histogram data from tf.summary.histogram. It shows some high-level statistics on a distribution. Each line on the chart represents a percentile in the distribution over the data: for example, the bottom line shows how the minimum value has changed over time, and the line in the middle shows how the median has changed. Reading from top to bottom, the lines have the following meaning: [maximum, 93%, 84%, 69%, 50%, 31%, 16%, 7%, minimum]\n",
    "\n",
    "    These percentiles can also be viewed as standard deviation boundaries on a normal distribution: [maximum, μ+1.5σ, μ+σ, μ+0.5σ, μ, μ-0.5σ, μ-σ, μ-1.5σ, minimum] so that the colored regions, read from inside to outside, have widths [σ, 2σ, 3σ] respectively.\n",
    "\n",
    "### Image Dashboard\n",
    "    The Image Dashboard can display pngs that were saved via a tf.summary.image. The dashboard is set up so that each row corresponds to a different tag, and each column corresponds to a run. Since the image dashboard supports arbitrary pngs, you can use this to embed custom visualizations (e.g. matplotlib scatterplots) into TensorBoard. This dashboard always shows you the latest image for each tag.\n",
    "\n",
    "### Audio Dashboard\n",
    "    The Audio Dashboard can embed playable audio widgets for audio saved via a tf.summary.audio. The dashboard is set up so that each row corresponds to a different tag, and each column corresponds to a run. This dashboard always embeds the latest audio for each tag.\n",
    "\n",
    "### Graph Explorer\n",
    "    The Graph Explorer can visualize a TensorBoard graph, enabling inspection of the TensorFlow model. To get best use of the graph visualizer, you should use name scopes to hierarchically group the ops in your graph - otherwise, the graph may be difficult to decipher. For more information, including examples, see the graph visualizer tutorial.\n",
    "\n",
    "### Embedding Projector\n",
    "    The Embedding Projector allows you to visualize high-dimensional data; for example, you may view your input data after it has been embedded in a high- dimensional space by your model. The embedding projector reads data from your model checkpoint file, and may be configured with additional metadata, like a vocabulary file or sprite images. \n",
    "\n",
    "### Text Dashboard\n",
    "    The Text Dashboard displays text snippets saved via tf.summary.text. Markdown features including hyperlinks, lists, and tables are all supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Steps \n",
    "\n",
    "    pip install tensorboard\n",
    "    (upgrade the torch,tensorboard,tensorflow)\n",
    "    pip install --upgrade torchvision\n",
    "    pip install --upgrade torch\n",
    "    pip install --upgrade tensorboard\n",
    "    pip install --upgrade tensorflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "     \n",
    "    supported versions \n",
    "    pytorch version - greater than 1.1.0\n",
    "    torchvision version  - greater than 0.3.0\n",
    "    tensorboard version - greater than 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example model\n",
    "\n",
    "Take any model and write model's output to tensorboard writer object . Writer will write the output to ./runs/ directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 15, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(15, 30, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(1080, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1(kernel=3, filters=15) 28x28x1 -> 26x26x15\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # conv2(kernel=3, filters=20) 26x26x15 -> 13x13x30\n",
    "        # max_pool(kernel=2) 13x13x30 -> 6x6x30\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2, stride=2))\n",
    "\n",
    "        # flatten 6x6x30 = 1080\n",
    "        x = x.view(-1, 1080)\n",
    "\n",
    "        # 1080 -> 100\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # 100 -> 10\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # transform to logits\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "grid = torchvision.utils.make_grid(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image('images', grid, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTClass(\n",
       "  (conv1): Conv2d(1, 15, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(15, 30, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (fc1): Linear(in_features=1080, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_num_correct(pred,Y):\n",
    "    return pred.argmax(dim=1).eq(Y).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar ,Histogram and Distribution Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 705 loss: 1.4361859418096996\n",
      "epoch 1 total_correct: 1193 loss: 0.3890482286612193\n",
      "epoch 2 total_correct: 1230 loss: 0.26689529028676806\n",
      "epoch 3 total_correct: 1271 loss: 0.17319698809158235\n",
      "epoch 4 total_correct: 1265 loss: 0.18897668538349016\n",
      "epoch 5 total_correct: 1281 loss: 0.14157835873109953\n",
      "epoch 6 total_correct: 1294 loss: 0.12438674350934369\n",
      "epoch 7 total_correct: 1288 loss: 0.1539668036358697\n",
      "epoch 8 total_correct: 1286 loss: 0.13928663588705517\n",
      "epoch 9 total_correct: 1298 loss: 0.1250829054486184\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for i,batch in enumerate(trainloader): \n",
    "        \n",
    "        X,Y = batch\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(pred,Y)\n",
    "        \n",
    "        if i>=20:\n",
    "            break\n",
    "            \n",
    "    writer.add_scalar('Loss', total_loss/(i+1), epoch)\n",
    "    writer.add_scalar('Number Correct', total_correct, epoch)\n",
    "    writer.add_scalar('Accuracy', total_correct /1344 , epoch)\n",
    "    \n",
    "    writer.add_histogram('conv1.bias', model.conv1.bias, epoch)\n",
    "    writer.add_histogram('conv1.weight', model.conv1.weight, epoch)\n",
    "    writer.add_histogram(\n",
    "        'conv1.weight.grad'\n",
    "        ,model.conv1.weight.grad\n",
    "        ,epoch\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        \"epoch\", epoch, \n",
    "        \"total_correct:\", total_correct, \n",
    "        \"loss:\", total_loss/(i+1)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try one of the following**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "import torch\n",
    "meta = []\n",
    "while len(meta)<100:\n",
    "    meta = meta+keyword.kwlist # get some strings\n",
    "meta = meta[:100]\n",
    "\n",
    "for i, v in enumerate(meta):\n",
    "    meta[i] = v+str(i)\n",
    "\n",
    "label_img = torch.rand(100, 3, 10, 32)\n",
    "for i in range(100):\n",
    "    label_img[i]*=i/100.0\n",
    "\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:100].float()\n",
    "\n",
    "label = dataset.test_labels[:100]\n",
    "features = images.view(100, 784)\n",
    "\n",
    "writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command for Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the  **tensorboard --logdir=runs** in command prompt.\n",
    "\n",
    "Open http://localhost:6006/ to see the results.\n",
    "\n",
    "To quit , press CRTL+C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Method**\n",
    "\n",
    "    Open from Jupyter-Notebook using magic comments\n",
    "    %load_ext tensorboard      \n",
    "    %tensorboard --logdir logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
